
#
# These sources are part of the "PyThon Programming Series" by Edgar Milvus, 
# you can find it on Amazon: https://www.amazon.com/dp/B0FTTQNXKG or
# https://tinyurl.com/PythonProgrammingSeries 
# New books info: https://linktr.ee/edgarmilvus 
#
# MIT License
# Copyright (c) 2025 Edgar Milvus
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# Source File: project_advanced_application_script.py
# Description: Advanced Application Script
# ==========================================

import os
import json
from typing import List
from pydantic import BaseModel, Field, conlist, ValidationError
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain_openai import ChatOpenAI

# --- 1. Define the Pydantic Schema (The Contract) ---

# Nested Model 1: Defines a structured security concern
class SecurityNote(BaseModel):
    """A specific security note identified during the review."""
    severity: str = Field(description="High, Medium, or Low.")
    description: str = Field(description="Detailed explanation of the security concern, including potential impact.")

# Nested Model 2: Defines a structured API endpoint detail
class APIEndpoint(BaseModel):
    """Details for a single API endpoint."""
    path: str = Field(description="The relative path of the API endpoint (e.g., /api/v1/users).")
    method: str = Field(description="HTTP method used (GET, POST, PUT, DELETE).")
    requires_auth: bool = Field(description="True if this endpoint requires authentication (e.g., JWT, API Key).")

# Root Model: The comprehensive structure for the documentation review output
class DocumentationReview(BaseModel):
    """Structured review results extracted from technical documentation."""
    project_name: str = Field(description="The formal name of the project.")
    required_libraries: conlist(str, min_items=1) = Field(
        description="A list of all primary external Python libraries required for runtime."
    )
    api_endpoints: List[APIEndpoint] = Field(description="A list of all documented API endpoints.")
    security_review: List[SecurityNote] = Field(
        default_factory=list,
        description="A list of all identified security notes. Can be empty if none found."
    )
    is_ready_for_production: bool = Field(
        description="Boolean indicating if the documentation suggests the system is stable and production-ready."
    )

# --- 2. Initialize Components ---

# CRITICAL: Ensure OPENAI_API_KEY is set in your environment
try:
    if not os.environ.get("OPENAI_API_KEY"):
        raise ValueError("OPENAI_API_KEY environment variable not set.")
except ValueError as e:
    print(f"Configuration Error: {e}")
    # In a real application, you would handle this gracefully or exit.

# Initialize the LLM (using a fast model for demonstration)
llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo")

# Initialize the Pydantic Output Parser with the target model
parser = PydanticOutputParser(pydantic_object=DocumentationReview)

# --- 3. Define the Prompt Template ---

# The format instructions generated by the parser are crucial.
format_instructions = parser.get_format_instructions()

# The prompt template instructs the LLM on its task and provides the required JSON structure.
prompt_template = """
You are an expert technical documentation reviewer. Your task is to analyze the provided raw technical summary
and extract structured data according to the specified output format.

1. Strictly adhere to the output format provided below.
2. If no security concerns are explicitly mentioned, return an empty list for 'security_review'.
3. Base your decision for 'is_ready_for_production' solely on the tone and content of the summary.

RAW TECHNICAL SUMMARY:
---
{summary_text}
---

OUTPUT FORMAT INSTRUCTIONS:
{format_instructions}

EXTRACTED STRUCTURED DATA:
"""

prompt = PromptTemplate(
    template=prompt_template,
    input_variables=["summary_text"],
    partial_variables={"format_instructions": format_instructions}
)

# --- 4. Input Data (Unstructured Text) ---

raw_summary = """
Project Hydra V1.2.
This system uses Python 3.11, relying heavily on FastAPI for routing and Requests for external calls.
We currently expose three main endpoints: /users/lookup (GET, requires JWT token),
/data/ingest (POST, no current authentication layer, needs review!), and /status (GET, no auth needed).
The system is stable but deployment documentation is still pending. We consider the core API complete.
A critical vulnerability (High severity) was noted in the initial design regarding SQL injection risks,
which needs immediate mitigation. We are targeting Q4 deployment, but the lack of auth on ingestion
and the SQL injection concern prevent this from being truly ready for production yet.
"""

# --- 5. Execution and Parsing ---

# Create the chain: Prompt | LLM
chain = prompt | llm

# Invoke the chain to get the raw string response (JSON formatted)
raw_response_text = chain.invoke({"summary_text": raw_summary}).content

# Use the parser to transform the raw text into a validated Pydantic object
try:
    validated_review: DocumentationReview = parser.parse(raw_response_text)
    
    # --- 6. Output and Validation Confirmation ---
    
    print("--- SUCCESS: Raw LLM Output Parsed and Validated ---")
    print(f"Type of validated object: {type(validated_review)}")
    print("\n--- Extracted Data Summary ---")
    print(f"Project: {validated_review.project_name}")
    print(f"Libraries: {', '.join(validated_review.required_libraries)}")
    print(f"Production Ready: {validated_review.is_ready_for_production}")
    print(f"Total API Endpoints Found: {len(validated_review.api_endpoints)}")
    print(f"Total Security Notes Found: {len(validated_review.security_review)}")
    
    # Demonstrate access to nested, validated data
    print("\n--- Detailed Security Review ---")
    for note in validated_review.security_review:
        print(f"  [Severity: {note.severity}] {note.description}")
        
    print("\n--- Detailed Endpoint Validation (Pydantic Object Check) ---")
    # Check the type of a nested element to confirm strict Pydantic parsing
    first_endpoint = validated_review.api_endpoints[0]
    print(f"First Endpoint Type: {type(first_endpoint)}")
    print(f"First Endpoint Path: {first_endpoint.path} (Auth Required: {first_endpoint.requires_auth})")

    # Attempt to serialize the validated object back to JSON (useful for API responses or storage)
    print("\n--- JSON Serialization Confirmation ---")
    print(json.dumps(validated_review.model_dump(), indent=2))

except ValidationError as e:
    print("\n--- FAILURE: Pydantic Validation Error ---")
    print("The LLM output did not conform to the defined schema.")
    print(e)
    
