
#
# These sources are part of the "PyThon Programming Series" by Edgar Milvus, 
# you can find it on Amazon: https://www.amazon.com/dp/B0FTTQNXKG or
# https://tinyurl.com/PythonProgrammingSeries 
# New books info: https://linktr.ee/edgarmilvus 
#
# MIT License
# Copyright (c) 2025 Edgar Milvus
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# Source File: solution_exercise_1.py
# Description: Solution for Exercise 1
# ==========================================

import os
from google import genai
from google.genai import types
import textwrap
import logging

# Set up logging to suppress potential warnings, if necessary, though generally not needed for genai.
# logging.basicConfig(level=logging.INFO)

# --- Configuration and Setup ---

# Ensure your GEMINI_API_KEY is set in your environment variables
try:
    # Initialize client, assumes GEMINI_API_KEY is available in the environment
    client = genai.Client()
except Exception as e:
    print(f"Error initializing client: {e}")
    print("Please ensure GEMINI_API_KEY is set in your environment variables.")
    exit()

MODEL_NAME = "gemini-2.5-flash"

# Configuration object to enable the code execution tool
CODE_EXECUTION_CONFIG = types.GenerateContentConfig(
    tools=[types.Tool(code_execution=types.ToolCodeExecution)]
)

def print_response_parts(response, title="Response Analysis"):
    """
    Helper function to clearly parse and print the multi-part response
    returned when the code execution tool is active, as detailed in the
    official documentation.
    """
    print("\n" + "="*80)
    print(f"[{title}]")
    print("="*80)

    if not response.candidates:
        print("No candidates found in the response.")
        return

    parts = response.candidates[0].content.parts
    print(f"Total parts received: {len(parts)}")

    for i, part in enumerate(parts):
        print(f"\n--- Part {i+1} ---")

        # 1. Text (LLM's Reasoning or Final Summary)
        if part.text is not None:
            print(f"TYPE: Text (Reasoning/Summary)")
            print(textwrap.fill(part.text, width=78))

        # 2. Executable Code (The code generated by the LLM)
        if part.executable_code is not None:
            print(f"TYPE: Executable Code ({part.executable_code.language})")
            print("----------------------------------------")
            print(part.executable_code.code.strip())
            print("----------------------------------------")

        # 3. Code Execution Result (The output from the sandboxed environment)
        if part.code_execution_result is not None:
            print(f"TYPE: Code Execution Result (Outcome: {part.code_execution_result.outcome.name})")
            print("OUTPUT:")
            # Indent output for clear readability
            output_lines = part.code_execution_result.output.strip().split('\n')
            if output_lines:
                print(textwrap.indent('\n'.join(output_lines), '  | '))
            else:
                print("  | (No visible output, potentially image data or silent execution)")

    print("\n" + "="*80)


# --- Exercise 1: Advanced Mathematical Calculation ---

def exercise_1_math_calculation():
    print("\n[Starting Exercise 1: Advanced Mathematical Calculation]")
    prompt = (
        "Calculate the result of the expression: "
        "The square root of 2025 plus the sum of cubes from 1 to 10. "
        "Generate and run Python code for the calculation."
    )

    response = client.models.generate_content(
        model=MODEL_NAME,
        contents=prompt,
        config=CODE_EXECUTION_CONFIG
    )

    print_response_parts(response, "Exercise 1: Math Calculation Result")


# --- Exercise 2: Data Processing and Library Utilization (Pandas) ---

def exercise_2_pandas_analysis():
    print("\n[Starting Exercise 2: Data Processing with Pandas]")
    prompt = (
        "I have a small dataset: 'Name,Score\\nAlice,92\\nBob,85\\nCharlie,78\\nDavid,95'. "
        "Write Python code using the pandas library to load this CSV string into a DataFrame, "
        "calculate the mean score, and print the result clearly labeled."
    )

    response = client.models.generate_content(
        model=MODEL_NAME,
        contents=prompt,
        config=CODE_EXECUTION_CONFIG
    )

    print_response_parts(response, "Exercise 2: Pandas Analysis Result")


# --- Exercise 3: Code Execution in a Chat Session ---

def exercise_3_chat_session():
    print("\n[Starting Exercise 3: Code Execution in a Chat Session]")

    # 1. Create a chat session with the tool enabled
    chat = client.chats.create(
        model=MODEL_NAME,
        config=CODE_EXECUTION_CONFIG
    )

    # 2. Initial message to establish context
    print("\nUSER: Initializing chat session...")
    initial_response = chat.send_message("I need help with a coding task.")
    print(f"GEMINI: {initial_response.text}")

    # 3. Subsequent message requiring code execution
    code_prompt = (
        "Generate a list of even numbers from 1 to 20, reverse the list, and print the result."
    )
    print(f"\nUSER: {code_prompt}")

    final_response = chat.send_message(code_prompt)

    # 4. Display the detailed parts of the final response
    print_response_parts(final_response, "Exercise 3: Chat Session Code Execution Result")


# --- Exercise 4: Challenging Modification - Visualization with Matplotlib ---

def exercise_4_matplotlib_plot():
    print("\n[Starting Exercise 4: Visualization with Matplotlib]")

    prompt = (
        "Generate 50 random numbers sampled from a normal distribution "
        "(mean 5, standard deviation 2) using numpy. "
        "Use the Matplotlib library to create and display a histogram of these 50 numbers. "
        "Ensure the plot is titled and labeled."
    )

    # NOTE: Matplotlib plots are returned as inline image data in the response.
    # The output parsing function will confirm the code ran successfully,
    # and the model's final text summary will confirm the plot was generated.
    response = client.models.generate_content(
        model=MODEL_NAME,
        contents=prompt,
        config=CODE_EXECUTION_CONFIG
    )

    print_response_parts(response, "Exercise 4: Matplotlib Visualization Result")


# --- Main Execution ---
if __name__ == "__main__":
    exercise_1_math_calculation()
    exercise_2_pandas_analysis()
    exercise_3_chat_session()
    exercise_4_matplotlib_plot()
