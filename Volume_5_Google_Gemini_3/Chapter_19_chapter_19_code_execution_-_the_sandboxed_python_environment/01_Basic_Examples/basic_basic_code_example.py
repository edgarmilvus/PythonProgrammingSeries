
#
# These sources are part of the "PyThon Programming Series" by Edgar Milvus, 
# you can find it on Amazon: https://www.amazon.com/dp/B0FTTQNXKG or
# https://tinyurl.com/PythonProgrammingSeries 
# New books info: https://linktr.ee/edgarmilvus 
#
# MIT License
# Copyright (c) 2025 Edgar Milvus
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# Source File: basic_basic_code_example.py
# Description: Basic Code Example
# ==========================================

# CODE_EXECUTION_EXAMPLE_01.py

# ----------------------------------------------------------------------
# 1. Setup and Configuration for Code Execution
# ----------------------------------------------------------------------
from google import genai
from google.genai import types
import os
import sys

# Define the model to be used. Gemini 2.5 models support code execution.
MODEL_NAME = "gemini-2.5-flash"

# Initialize the client (assumes GEMINI_API_KEY is set in environment)
try:
    # A robust application should handle missing API keys gracefully
    client = genai.Client()
except Exception as e:
    print(f"Error initializing Gemini Client: {e}")
    print("Please ensure the GEMINI_API_KEY environment variable is set.")
    # Use sys.exit() for immediate, controlled program termination
    sys.exit(1)

# Define the configuration object to explicitly enable the Code Execution tool.
# This is the crucial step that activates the sandboxed environment for the model.
# We pass the types.ToolCodeExecution object as a value to the code_execution key
# within a types.Tool object list.
code_execution_config = types.GenerateContentConfig(
    tools=[types.Tool(code_execution=types.ToolCodeExecution())]
)

# ----------------------------------------------------------------------
# 2. Define the Prompt and Execute the Request
# ----------------------------------------------------------------------
# The prompt must clearly instruct the model to use code for calculation.
prompt_text = (
    "Calculate the standard deviation of the following list of numbers: "
    "[12, 15, 18, 21, 24, 27, 30]. "
    "Use the Python `statistics` library for accuracy. "
    "Generate and execute the required Python code."
)

print(f"--- Sending Prompt to Gemini ({MODEL_NAME}, Code Execution Enabled) ---\n'{prompt_text}'\n")

# Send the request to the model
response = client.models.generate_content(
    model=MODEL_NAME,
    contents=prompt_text,
    config=code_execution_config,
)

# ----------------------------------------------------------------------
# 3. Process and Display the Multi-Part Response
# ----------------------------------------------------------------------
print("\n" + "=" * 60)
print("--- Detailed Response Parts (Parsing the Candidate Content) ---")
print("=" * 60)

# Check for successful response generation
if not response.candidates or not response.candidates[0].content:
    print("Error: No content or candidates returned in the response.")
    sys.exit(1)

# Iterate through the content parts to separate the model's reasoning,
# the generated code, and the output from the sandbox.
for i, part in enumerate(response.candidates[0].content.parts):
    
    # 3a. Display Text (Model's reasoning, explanation, or summary)
    if part.text:
        print(f"\n[Part {i+1}: Model Reasoning/Text]")
        print("-" * 40)
        print(part.text.strip())

    # 3b. Display Executable Code (The script generated by the model)
    if part.executable_code and part.executable_code.code:
        print(f"\n[Part {i+1}: Sandboxed Code (Executable)]")
        print("-" * 40)
        # The API confirms the language, which is fixed as PYTHON in the sandbox
        print(f"Language: {part.executable_code.language}")
        print("-" * 40)
        # Print the code block itself
        print(part.executable_code.code.strip())

    # 3c. Display Code Execution Result (Output from the sandbox)
    if part.code_execution_result and part.code_execution_result.output:
        print(f"\n[Part {i+1}: Sandbox Output (Result)]")
        print("-" * 40)
        # The 'outcome' field confirms if the execution was successful (OUTCOME_OK)
        print(f"Execution Outcome: {part.code_execution_result.outcome}")
        print("-" * 40)
        # Print the standard output (stdout) captured from the execution
        print(part.code_execution_result.output.strip())

# ----------------------------------------------------------------------
# 4. Final Summary (Model's concluding text, accessible via response.text)
# ----------------------------------------------------------------------
# This is often the final, consolidated answer based on the execution result.
final_summary = response.text
if final_summary:
    print("\n" + "=" * 60)
    print("--- Consolidated Final Answer (response.text) ---")
    print("=" * 60)
    print(final_summary.strip())
